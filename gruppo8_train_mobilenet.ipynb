{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gruppo8_train_mobilenet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1Xj3w_lYMbBj"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChPkqLUoppCF"
      },
      "source": [
        "# SETTINGS \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldajibMypw_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c54cd6-e9f6-44f0-ae16-5c4f09af4cdf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwqRegYgpxzM"
      },
      "source": [
        "#folder of dataset\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3g3taWSvPiD"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import concatenate\n",
        "import numpy as np\n",
        "import argparse\n",
        "import locale\n",
        "import os\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications import VGG16\n",
        "import h5py\n",
        "from random import *\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "import random\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import concatenate,Input,Dense,Conv2D,MaxPool2D,Dropout,Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.models import load_model,Model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUhe-pT8LO16"
      },
      "source": [
        "# OPEN DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz7_-y4s-1wH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61555d1b-0b4e-464a-ba11-df167d7ef16e"
      },
      "source": [
        "f=h5py.File('dataset_160.h5', 'r')\n",
        "x_train = f['training']\n",
        "x_valid = f['validation']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(123839, 160, 160, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbHkhEALrh-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d43fa56-2525-45b7-9bdf-20ba27f026e0"
      },
      "source": [
        "f_label=h5py.File('label_160.h5', 'r')\n",
        "y_train = f_label['label_training']\n",
        "y_valid = f_label['label_validation']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(123839, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6hHDiwXscvN"
      },
      "source": [
        "#Number of samples\n",
        "n_val = x_valid.shape[0]\n",
        "n_train = x_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBSUVaCjOb_F"
      },
      "source": [
        "# CREATE BATCHES WITH RANDOM TRANSFORMATIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDBgQ3J3W4jf"
      },
      "source": [
        "#DATA AUGMENTATION\n",
        "datagen = ImageDataGenerator(\n",
        "   rotation_range=10,\n",
        "   brightness_range=(0.7,1.5),\n",
        "   horizontal_flip=True\n",
        ")\n",
        "\n",
        "apply_transfom=0\n",
        "\n",
        "#BATCHES FOR TRAINING SET \n",
        "def generate_random_batches(X_train, y_data, size, stddev, batch_size, shape):\n",
        "  start = True\n",
        "  height=shape[0]\n",
        "  width=shape[1]\n",
        "  channel=shape[2]\n",
        "  (n, h, w, c)=X_train.shape\n",
        "  bs = batch_size\n",
        "  indices = []\n",
        "  iteration = 0\n",
        "  index = randint(0, n)\n",
        "  index_array = []\n",
        "  apply_transfom=0\n",
        "\n",
        "  if size % bs != 0:\n",
        "    steps = size // bs + 1\n",
        "    one_more_time = True \n",
        "  else:\n",
        "    steps = size // bs\n",
        "    one_more_time = False \n",
        "  print(X_train.shape)\n",
        "  while True:\n",
        "    \n",
        "    #IN CASE OF THE LAST BATCH CONTAINS LESS THEN \"batch_size\" elements\n",
        "    if iteration == steps-1 and one_more_time:\n",
        "      num_elem = n - bs * (steps-1)\n",
        "      X_batch = np.empty (shape=(num_elem, height, width, channel))\n",
        "      y_batch = np.empty (shape=(num_elem, 101))\n",
        "      X_batch_ordered = np.empty (shape=(num_elem, height, width, channel))\n",
        "      y_batch_ordered = np.empty (shape=(num_elem, 101))\n",
        "\n",
        "    else:\n",
        "      num_elem = bs\n",
        "      X_batch = np.empty (shape=(bs, height, width, channel))\n",
        "      y_batch = np.empty (shape=(bs, 101))\n",
        "      X_batch_ordered = np.empty (shape=(bs, height, width, channel))\n",
        "      y_batch_ordered = np.empty (shape=(bs, 101))\n",
        "    \n",
        "    #BATCHES ARE TAKEN IN CIRCULAR ORDER STARTING FROM A RANDOM INDEX\n",
        "    for i in range (num_elem):\n",
        "      X_batch_ordered[i] = X_train[(index+i) % n]\n",
        "      y_batch_ordered[i] = y_data[(index+i) % n]\n",
        "    \n",
        "    index_array = []\n",
        "    for i in range (num_elem):\n",
        "      index_array.insert(i, i)\n",
        "    \n",
        "    random.shuffle(index_array)\n",
        "    \n",
        "    #SHUFFLE ELEMENTS INSIDE THE BATCH AND APPLY TRANSFORMATIONS\n",
        "    for i in range (num_elem):\n",
        "      if random.randint(0, 4) == 1:\n",
        "        X_batch[i] = datagen.random_transform(X_batch_ordered[index_array[i]])\n",
        "      else:\n",
        "        X_batch[i] = X_batch_ordered[index_array[i]]\n",
        "      y_batch [i] = y_batch_ordered[index_array[i]]\n",
        "  \n",
        "\n",
        "    if iteration == steps-1:\n",
        "      iteration = 0\n",
        "      index = randint(0, n)\n",
        "    else:\n",
        "      iteration = iteration + 1\n",
        "      index = (index + bs) % n\n",
        "\n",
        "\n",
        "    yield X_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cCtkGPASCjz"
      },
      "source": [
        "# DEFINE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwxdUkrjhY5b"
      },
      "source": [
        "import keras.backend as K\n",
        "def contrastive_accuracy(y_true, y_pred):\n",
        "    return  1.0-K.mean(K.max(abs(y_pred-y_true),axis=1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beSunoWYvFsG"
      },
      "source": [
        "input_shape = (160, 160, 3)\r\n",
        "model_mobilenet = keras.applications.mobilenet_v2.MobileNetV2(input_shape=input_shape , alpha = 0.75, include_top=False, weights='imagenet', pooling = 'avg')\r\n",
        "model_mobilenet.trainable=True\r\n",
        "input_dim=(160, 160, 3)\r\n",
        "img_a = Input(shape=input_dim)\r\n",
        "\r\n",
        "feat_vecs = model_mobilenet(img_a)\r\n",
        "print(feat_vecs.shape)\r\n",
        "\r\n",
        "d1=Dense(512,activation='relu')(feat_vecs)\r\n",
        "d1=Dropout(rate=0.20)(d1)\r\n",
        "\r\n",
        "d2=Dense(128,activation='relu')(d1)\r\n",
        "d2=Dropout(rate=0.20)(d2)\r\n",
        "\r\n",
        "d3=Dense(101,activation='softmax')(d2)\r\n",
        "\r\n",
        "model=Model(inputs=img_a, outputs=d3)\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "optimizer = keras.optimizers.Adam()\r\n",
        "model.compile(loss='categorical_crossentropy',optimizer = optimizer,metrics=['accuracy', contrastive_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE3oSh-gSn48"
      },
      "source": [
        "# TRAIN MODEL "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rTPtVmJLnWo"
      },
      "source": [
        "# Early stopping\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience = 4, min_lr = 0.00001)\n",
        "\n",
        "checkpoints_loss = ModelCheckpoint('mobilenet_age_Loss.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
        "checkpoints_acc = ModelCheckpoint('mobilenet_age_Acc.h5', monitor='val_contrastive_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True), reduce_lr, checkpoints_loss, checkpoints_acc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwqpkO35hoH5"
      },
      "source": [
        "batch_size=100\n",
        "print(n_val)\n",
        "print(n_train)\n",
        "resume=0\n",
        "\n",
        "if n_train % batch_size != 0:\n",
        "  steps_per_epoch = n_train//batch_size + 1 \n",
        "else:\n",
        "  steps_per_epoch = n_train//batch_size \n",
        "\n",
        "\n",
        "if n_val % batch_size != 0:\n",
        "  validation_steps = n_val//batch_size + 1\n",
        "else:\n",
        "  validation_steps = n_val//batch_size\n",
        "\n",
        "if resume:\n",
        "  model.load_weights('gruppo8_mobilenet.h5')\n",
        "\n",
        "model.fit(generate_random_batches(x_train, y_train, n_train, 2.0, batch_size, input_shape), \n",
        "              steps_per_epoch= steps_per_epoch,\n",
        "              validation_data=(x_valid, y_valid),\n",
        "              validation_steps=validation_steps,\n",
        "              epochs=1000,\n",
        "              callbacks=callbacks\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}